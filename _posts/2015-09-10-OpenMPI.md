---
layout: post
title: "Introduction to OpenMPI"
author: ramiro_chg
modified:
excerpt: "Fortran and OpenMPI"
tags: [MPI, Fortran]
image:
  feature: sample-image-2.jpg
---


<section id="table-of-contents" class="toc">
  <header>
    <h3>Table of Contents</h3>
  </header>
<div id="drawer" markdown="1">
*  Auto generated table of contents
{:toc}
</div>
</section><!-- /#table-of-contents -->


### Introduction

This post is a short tutorial on OpenMPI. The main goals are be familiar with the
general concepts and terminology used on MPI parallel programming. The examples of code shown
in this tutorial are Fortran 90.

We have to realize that there are three important elements on parallel programing in cluster systems: hardware, software and the topology of the network. This tutorial is focused mainly on clusters that are build of nodes. This means that each node does NOT have direct access to the other node memory (we have a distributed memory and not common shared memory). The  consequence is that we will need to communicate between nodes and send and collect information/data from different machinesm, that is why it is used MPI directives. However note that the code produced with MPI can be used on a single processor or in a multicore machine.

### Definitions

#### FLOPS

It is the number of floating point operations per second. It is used to describe
the computation capability. 

#### Flynn's Taxonomy

- SISD: single instruction single data (serial computer)
- SIMD: single instruction multiple data (vector computer)
- MISD: multiple instruction single data (uncommon)
- MIMD: multiple instruction multiple data (parallel computer).

We will use the terminology SPMD to mean single program multiple data. The idea is a commom code runned on several computers but each node process different data (the data of each node should be distribuited by the single code). MPI is a realization of the  SPMD by implementing several directives. In the practical Fortran 90 programming it is a module called with USE MPI and it implement several subroutines that manage the SPMD idea. The typical workflow is build a source code, compile it (in the case of Fortran 90 or C/C++ etc), and run in a machine indicating the number of tasks (or nodes) that will be used (for instance mpirun -np 123 mycode.exe). 

#### Performance related concepts

- Serial time: time to run the code in 1 machine (serial code): ts
- Parallel time: time to process the same code with p processors: tp
- Speedup factor: S(p)=ts/tp
- Work cost: W(p)=p*tp
- Efficiency: E(p)=ts/(p*tp)=W(1)/W(p)
- Serial fraction: f, is the fraction of the code that is allways serial (it is allways runned
by only 1 processor).
- Overhead: (Wp-W1)/W1
- Computation time: fraction of time running the code (tc)
- Comunication time: fraction of the time performing transmission or comunication between nodes and memory (tt)

Note: it is important maximize tc/tt

#### Amdahl's law

$$t_{p}=f*t_{s}+(1-f)\frac{t_{s}}{p}$$

S(p)=p/(f(p-1)+1)

####Guftafson's law

ts=f*tp+(1-f)*p*tp
S(p)=f+(1-f)*p


{%highlight fortran%}
program main
    use mpi
    integer :: ierr, nproc, iproc
    call MPI_INIT(ierr)
    call MPI_COMM_RANK(MPI_COMM_WORLD, iproc, ierr)
    call MPI_COMM_SIZE(MPI_COMM_WORLD, nproc, ierr)
    print *, 'Hello World! by ',iproc,'from ',nproc
    call MPI_FINALIZE(ierr)
end program main
{%endhighlight%}
